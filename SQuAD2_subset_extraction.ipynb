{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2035957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SQuAD v2 dataset...\n",
      "Number of examples in the dataset: 130319\n",
      "First example in the dataset: {'id': '56be85543aeaaa14008c9063', 'title': 'Beyonc√©', 'context': 'Beyonc√© Giselle Knowles-Carter (/biÀêÀàj…ínse…™/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyonc√©\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".', 'question': 'When did Beyonce start becoming popular?', 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}\n",
      "\n",
      "Extracting 0.5% of each dataset split...\n",
      "Original train size: 130319\n",
      "0.5% train size: 651\n",
      "Original validation size: 11873\n",
      "0.5% test size: 59\n",
      "\n",
      "Final dataset sizes:\n",
      "Train: 651\n",
      "Test: 59\n",
      "\n",
      "Saving dataset to squad_v2_05percent/...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eee30dc40d14f1b9803b7badb950201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train split to squad_v2_05percent\\train.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9263056bcd514fb5b75371ee8e83f448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test split to squad_v2_05percent\\test.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83927a36bfcd412db7fa8ebc0adf2439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/651 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0115a43969974ca980f3513c5bafd129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/59 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved complete dataset to squad_v2_05percent\n",
      "\n",
      "Train example: When did Beyonce start becoming popular?\n",
      "Test example: In what country is Normandy located?\n",
      "\n",
      "Dataset extraction and saving completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import json\n",
    "\n",
    "# Create directory for storing the dataset\n",
    "dataset_dir = \"squad_v2_05percent\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# Load the SQuAD v2 dataset using the Hugging Face datasets library\n",
    "print(\"Loading SQuAD v2 dataset...\")\n",
    "dataset = load_dataset(\"squad_v2\")\n",
    "print(\"Number of examples in the dataset:\", len(dataset[\"train\"]))\n",
    "print(\"First example in the dataset:\", dataset[\"train\"][0])\n",
    "\n",
    "# Extract 0.5% of each split\n",
    "print(\"\\nExtracting 0.5% of each dataset split...\")\n",
    "\n",
    "# Calculate 0.5% sizes\n",
    "train_size = int(len(dataset[\"train\"]) * 0.005)\n",
    "test_size = int(len(dataset[\"validation\"]) * 0.005)  # Use validation as test\n",
    "\n",
    "print(f\"Original train size: {len(dataset['train'])}\")\n",
    "print(f\"0.5% train size: {train_size}\")\n",
    "print(f\"Original validation size: {len(dataset['validation'])}\")\n",
    "print(f\"0.5% test size: {test_size}\")\n",
    "\n",
    "# Create 0.5% subsets with only train and test\n",
    "dataset_05percent = DatasetDict({\n",
    "    \"train\": dataset[\"train\"].select(range(train_size)),\n",
    "    \"test\": dataset[\"validation\"].select(range(test_size))\n",
    "})\n",
    "\n",
    "# Print final sizes\n",
    "print(f\"\\nFinal dataset sizes:\")\n",
    "print(f\"Train: {len(dataset_05percent['train'])}\")\n",
    "print(f\"Test: {len(dataset_05percent['test'])}\")\n",
    "\n",
    "# Save each split to separate files\n",
    "print(f\"\\nSaving dataset to {dataset_dir}/...\")\n",
    "\n",
    "# Save as JSON files\n",
    "for split_name, split_data in dataset_05percent.items():\n",
    "    filepath = os.path.join(dataset_dir, f\"{split_name}.json\")\n",
    "    split_data.to_json(filepath)\n",
    "    print(f\"Saved {split_name} split to {filepath}\")\n",
    "\n",
    "# Also save using Hugging Face datasets format (recommended)\n",
    "dataset_05percent.save_to_disk(dataset_dir)\n",
    "print(f\"Saved complete dataset to {dataset_dir}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"original_train_size\": len(dataset[\"train\"]),\n",
    "    \"original_validation_size\": len(dataset[\"validation\"]),\n",
    "    \"extracted_train_size\": len(dataset_05percent[\"train\"]),\n",
    "    \"extracted_test_size\": len(dataset_05percent[\"test\"]),\n",
    "    \"extraction_percentage\": 0.5\n",
    "}\n",
    "\n",
    "with open(os.path.join(dataset_dir, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "# Show examples from each split\n",
    "print(f\"\\nTrain example: {dataset_05percent['train'][0]['question']}\")\n",
    "print(f\"Test example: {dataset_05percent['test'][0]['question']}\")\n",
    "\n",
    "print(\"\\nDataset extraction and saving completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1fde7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SQuAD v2 dataset...\n",
      "Number of examples in the dataset: 130319\n",
      "First example in the dataset: {'id': '56be85543aeaaa14008c9063', 'title': 'Beyonc√©', 'context': 'Beyonc√© Giselle Knowles-Carter (/biÀêÀàj…ínse…™/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyonc√©\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".', 'question': 'When did Beyonce start becoming popular?', 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}\n",
      "\n",
      "Extracting 0.1% of each dataset split...\n",
      "Original train size: 130319\n",
      "0.1% train size: 130\n",
      "Original validation size: 11873\n",
      "0.1% test size: 11\n",
      "Creating random subsets...\n",
      "\n",
      "Final dataset sizes:\n",
      "Train: 130\n",
      "Test: 11\n",
      "\n",
      "Answerable questions:\n",
      "Train: 94/130 (72.3%)\n",
      "Test: 3/11 (27.3%)\n",
      "\n",
      "Saving dataset to squad_v2_01percent/...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f284fb82984d0fa0cc3f9a2a607b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train split to squad_v2_01percent\\train.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94ac31194724aa6ba7374995b73a742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test split to squad_v2_01percent\\test.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f726ad39d36421c9b80ca0a36fb3722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/130 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa050da32f9f44758e61b2ad8b8257c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved complete dataset to squad_v2_01percent\n",
      "\n",
      "Example data:\n",
      "Train question: What century did Nasser rule in?\n",
      "Train context: Nasser remains an iconic figure in the Arab world, particularly for his strides towards social justi...\n",
      "Train answer: {'text': ['20th'], 'answer_start': [667]}\n",
      "\n",
      "Test question: How many State of California University campuses are there?\n",
      "Test context: The Tech Coast is a moniker that has gained use as a descriptor for the region's diversified technol...\n",
      "Test answer: {'text': [], 'answer_start': []}\n",
      "\n",
      "‚úÖ Dataset extraction and saving completed!\n",
      "üìÅ Dataset saved to: c:\\Users\\manua\\Desktop\\BigData\\Project\\SelfPlagAI\\squad_v2_01percent\n",
      "üìä Total examples: 141\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Create directory for storing the dataset\n",
    "dataset_dir = \"squad_v2_01percent\"  # Changed directory name\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# Load the SQuAD v2 dataset using the Hugging Face datasets library\n",
    "print(\"Loading SQuAD v2 dataset...\")\n",
    "dataset = load_dataset(\"squad_v2\")\n",
    "print(\"Number of examples in the dataset:\", len(dataset[\"train\"]))\n",
    "print(\"First example in the dataset:\", dataset[\"train\"][0])\n",
    "\n",
    "# Extract 0.1% of each split\n",
    "print(\"\\nExtracting 0.1% of each dataset split...\")\n",
    "\n",
    "# Calculate 0.1% sizes\n",
    "train_size = int(len(dataset[\"train\"]) * 0.001)  # Changed from 0.005 to 0.001\n",
    "test_size = int(len(dataset[\"validation\"]) * 0.001)  # Changed from 0.005 to 0.001\n",
    "\n",
    "print(f\"Original train size: {len(dataset['train'])}\")\n",
    "print(f\"0.1% train size: {train_size}\")\n",
    "print(f\"Original validation size: {len(dataset['validation'])}\")\n",
    "print(f\"0.1% test size: {test_size}\")\n",
    "\n",
    "# Create 0.1% subsets with random sampling for better representation\n",
    "print(\"Creating random subsets...\")\n",
    "train_indices = random.sample(range(len(dataset[\"train\"])), train_size)\n",
    "test_indices = random.sample(range(len(dataset[\"validation\"])), test_size)\n",
    "\n",
    "dataset_01percent = DatasetDict({  # Changed variable name\n",
    "    \"train\": dataset[\"train\"].select(train_indices),\n",
    "    \"test\": dataset[\"validation\"].select(test_indices)\n",
    "})\n",
    "\n",
    "# Print final sizes and statistics\n",
    "print(f\"\\nFinal dataset sizes:\")\n",
    "print(f\"Train: {len(dataset_01percent['train'])}\")\n",
    "print(f\"Test: {len(dataset_01percent['test'])}\")\n",
    "\n",
    "# Check for answerable vs unanswerable questions (SQuAD v2 feature)\n",
    "train_answerable = sum(1 for ex in dataset_01percent['train'] if len(ex['answers']['text']) > 0)\n",
    "test_answerable = sum(1 for ex in dataset_01percent['test'] if len(ex['answers']['text']) > 0)\n",
    "\n",
    "print(f\"\\nAnswerable questions:\")\n",
    "print(f\"Train: {train_answerable}/{len(dataset_01percent['train'])} ({train_answerable/len(dataset_01percent['train'])*100:.1f}%)\")\n",
    "print(f\"Test: {test_answerable}/{len(dataset_01percent['test'])} ({test_answerable/len(dataset_01percent['test'])*100:.1f}%)\")\n",
    "\n",
    "# Save each split to separate files\n",
    "print(f\"\\nSaving dataset to {dataset_dir}/...\")\n",
    "\n",
    "# Save as JSON files\n",
    "for split_name, split_data in dataset_01percent.items():\n",
    "    filepath = os.path.join(dataset_dir, f\"{split_name}.json\")\n",
    "    split_data.to_json(filepath)\n",
    "    print(f\"Saved {split_name} split to {filepath}\")\n",
    "\n",
    "# Also save using Hugging Face datasets format (recommended)\n",
    "dataset_01percent.save_to_disk(dataset_dir)\n",
    "print(f\"Saved complete dataset to {dataset_dir}\")\n",
    "\n",
    "# Save enhanced metadata\n",
    "metadata = {\n",
    "    \"original_train_size\": len(dataset[\"train\"]),\n",
    "    \"original_validation_size\": len(dataset[\"validation\"]),\n",
    "    \"extracted_train_size\": len(dataset_01percent[\"train\"]),\n",
    "    \"extracted_test_size\": len(dataset_01percent[\"test\"]),\n",
    "    \"extraction_percentage\": 0.1,  # Changed from 0.5 to 0.1\n",
    "    \"sampling_method\": \"random\",\n",
    "    \"seed\": 42,\n",
    "    \"train_answerable\": train_answerable,\n",
    "    \"test_answerable\": test_answerable,\n",
    "    \"train_answerable_percentage\": train_answerable/len(dataset_01percent['train'])*100,\n",
    "    \"test_answerable_percentage\": test_answerable/len(dataset_01percent['test'])*100,\n",
    "    \"dataset_format\": \"squad_v2\",\n",
    "    \"splits\": [\"train\", \"test\"]\n",
    "}\n",
    "\n",
    "with open(os.path.join(dataset_dir, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "# Show examples from each split\n",
    "print(f\"\\nExample data:\")\n",
    "print(f\"Train question: {dataset_01percent['train'][0]['question']}\")\n",
    "print(f\"Train context: {dataset_01percent['train'][0]['context'][:100]}...\")\n",
    "print(f\"Train answer: {dataset_01percent['train'][0]['answers']}\")\n",
    "print(f\"\\nTest question: {dataset_01percent['test'][0]['question']}\")\n",
    "print(f\"Test context: {dataset_01percent['test'][0]['context'][:100]}...\")\n",
    "print(f\"Test answer: {dataset_01percent['test'][0]['answers']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset extraction and saving completed!\")\n",
    "print(f\"üìÅ Dataset saved to: {os.path.abspath(dataset_dir)}\")\n",
    "print(f\"üìä Total examples: {len(dataset_01percent['train']) + len(dataset_01percent['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218ff2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
